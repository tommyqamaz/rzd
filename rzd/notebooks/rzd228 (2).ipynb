{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:26:34.247209Z","iopub.execute_input":"2022-07-19T13:26:34.248111Z","iopub.status.idle":"2022-07-19T13:26:44.976361Z","shell.execute_reply.started":"2022-07-19T13:26:34.247976Z","shell.execute_reply":"2022-07-19T13:26:44.975184Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import Tuple, List\n\nimport albumentations as A\nimport cv2\nimport numpy as np\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport segmentation_models_pytorch as smp\nfrom albumentations.pytorch import ToTensorV2\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchmetrics import Dice\nfrom torchmetrics import MetricCollection","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:20.048772Z","iopub.execute_input":"2022-07-19T13:40:20.049229Z","iopub.status.idle":"2022-07-19T13:40:20.058068Z","shell.execute_reply.started":"2022-07-19T13:40:20.049190Z","shell.execute_reply":"2022-07-19T13:40:20.056937Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from os import path\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport wandb\nfrom pytorch_lightning.loggers import WandbLogger","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:20.907975Z","iopub.execute_input":"2022-07-19T13:40:20.909192Z","iopub.status.idle":"2022-07-19T13:40:20.915392Z","shell.execute_reply.started":"2022-07-19T13:40:20.909110Z","shell.execute_reply":"2022-07-19T13:40:20.914057Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"wandb_logger = WandbLogger(project=\"RZD\", name=\"v0_unetpp\", log_model=\"all\")","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:21.846288Z","iopub.execute_input":"2022-07-19T13:40:21.847388Z","iopub.status.idle":"2022-07-19T13:40:35.655082Z","shell.execute_reply.started":"2022-07-19T13:40:21.847336Z","shell.execute_reply":"2022-07-19T13:40:35.652884Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\nNUM_WORKERS = 8\nLOSS = \"dice\"\nOPTIMIZER = \"Adam\"\nLEARNING_RATE = 3e-4\nWEIGHT_DECAY = 1e-6\nSCHEDULER = None\nMIN_LR = 1e-6\n\nFAST_DEV_RUN = False # Debug training\nGPUS = 1\nMAX_EPOCHS = 20","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:38.004433Z","iopub.execute_input":"2022-07-19T13:40:38.005235Z","iopub.status.idle":"2022-07-19T13:40:38.015655Z","shell.execute_reply.started":"2022-07-19T13:40:38.005196Z","shell.execute_reply":"2022-07-19T13:40:38.014523Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"CLASSES = {0:'background', 7: 'railway', 6: 'other railways', 10: 'trains'}\nMAP_MASKS = {7: 1, 6: 2, 10: 3, 0: 0}\nMAP_SUBMIT = {1: 7, 2: 6, 3: 10, 0: 0}\n\nTRAIN_DATASET_PATH = '../input/train-dataset/train_dataset_train/train'\nTRAIN_PATH = {'images': path.join(TRAIN_DATASET_PATH, 'images'), 'mask': path.join(TRAIN_DATASET_PATH, 'mask')}\nALL_MASKS = glob.glob(path.join(TRAIN_PATH['mask'], '*.png'))\nALL_IMAGES = glob.glob(path.join(TRAIN_PATH['images'], '*.png'))","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:38.711981Z","iopub.execute_input":"2022-07-19T13:40:38.712625Z","iopub.status.idle":"2022-07-19T13:40:38.784080Z","shell.execute_reply.started":"2022-07-19T13:40:38.712577Z","shell.execute_reply":"2022-07-19T13:40:38.783181Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"LOSS_FNS = {\n    \"bce\": smp.losses.SoftBCEWithLogitsLoss(),\n    \"dice\": smp.losses.DiceLoss(mode=\"multiclass\"),\n    \"focal\": smp.losses.FocalLoss(mode=\"multiclass\"),\n    \"jaccard\": smp.losses.JaccardLoss(mode=\"multiclass\"),\n    \"lovasz\": smp.losses.LovaszLoss(mode=\"multiclass\"),\n    \"tversky\": smp.losses.TverskyLoss(mode=\"multiclass\"),}","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:40.016023Z","iopub.execute_input":"2022-07-19T13:40:40.017322Z","iopub.status.idle":"2022-07-19T13:40:40.034696Z","shell.execute_reply.started":"2022-07-19T13:40:40.017272Z","shell.execute_reply":"2022-07-19T13:40:40.032645Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class RZDDataset(Dataset):\n    def __init__(self, image_paths: List[Path] = ALL_IMAGES, mask_paths: List[Path] = ALL_MASKS, transforms: Callable = None):        \n        self.image_paths = image_paths\n\n        self.mask_paths = mask_paths\n\n        self.transforms = transforms\n\n    def __len__(self) -> int:\n        return len(self.image_paths)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        image_path = self.image_paths[idx]\n        mask_path = self.mask_paths[idx]\n\n        image = self._load_image(image_path)\n        mask = self._load_mask(mask_path)\n        if self.transforms is not None:\n            data = self.transforms(image=image, mask=mask)\n            image, mask = data[\"image\"], data[\"mask\"]\n\n        return image, mask\n\n    @staticmethod\n    def _load_image(image_path: Path) -> np.ndarray:\n        return cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n\n    @staticmethod\n    def _load_mask(mask_path: Path) -> np.ndarray:\n        transorm_mask = np.vectorize(lambda x: MAP_MASKS[x])\n        return transorm_mask(cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE))","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:41.104838Z","iopub.execute_input":"2022-07-19T13:40:41.105621Z","iopub.status.idle":"2022-07-19T13:40:41.124548Z","shell.execute_reply.started":"2022-07-19T13:40:41.105578Z","shell.execute_reply":"2022-07-19T13:40:41.123463Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"ds = RZDDataset()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:41.763543Z","iopub.execute_input":"2022-07-19T13:40:41.763940Z","iopub.status.idle":"2022-07-19T13:40:41.771357Z","shell.execute_reply.started":"2022-07-19T13:40:41.763909Z","shell.execute_reply":"2022-07-19T13:40:41.770034Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def show_examples(name: str, pair: np.array):\n    plt.figure(figsize=(10, 14))\n    plt.subplot(1, 2, 1)\n    plt.imshow(pair[1])\n    plt.title(f\"Image: {name}\")\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(pair[0])\n    plt.title(f\"Mask: {name}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:42.288069Z","iopub.execute_input":"2022-07-19T13:40:42.288828Z","iopub.status.idle":"2022-07-19T13:40:42.297192Z","shell.execute_reply.started":"2022-07-19T13:40:42.288788Z","shell.execute_reply":"2022-07-19T13:40:42.295836Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"show_examples('train', ds[34])","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:42.906974Z","iopub.execute_input":"2022-07-19T13:40:42.907685Z","iopub.status.idle":"2022-07-19T13:40:44.174740Z","shell.execute_reply.started":"2022-07-19T13:40:42.907646Z","shell.execute_reply":"2022-07-19T13:40:44.173462Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"show_examples('train', ds[32])","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:44.177267Z","iopub.execute_input":"2022-07-19T13:40:44.177934Z","iopub.status.idle":"2022-07-19T13:40:46.358388Z","shell.execute_reply.started":"2022-07-19T13:40:44.177894Z","shell.execute_reply":"2022-07-19T13:40:46.357350Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"show_examples('train', ds[123])","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:46.360350Z","iopub.execute_input":"2022-07-19T13:40:46.361196Z","iopub.status.idle":"2022-07-19T13:40:47.571487Z","shell.execute_reply.started":"2022-07-19T13:40:46.361155Z","shell.execute_reply":"2022-07-19T13:40:47.570417Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class RZDDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        dataset = RZDDataset,\n        all_images: List[Path] = ALL_IMAGES,\n        all_masks: List[Path] = ALL_MASKS,\n        train_size_coef: int = 0.8,\n        batch_size: int = 8,\n        num_workers: int = 2,\n        input_shape: Tuple[int, int] = (512, 512)\n    ):\n        super().__init__()\n        \n        self.dataset = dataset\n        self.all_images = all_images\n        self.all_masks = all_masks\n        self.save_hyperparameters()\n\n        self.train_transforms, self.val_transforms = self._init_transforms()\n\n    def _init_transforms(self) -> Tuple[Callable, Callable]:\n        train_transforms = [\n            A.Resize(*self.hparams.input_shape),\n            A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n            ToTensorV2(),\n            \n        ]\n\n        val_transforms = [\n            A.Resize(*self.hparams.input_shape),\n            A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n            ToTensorV2(),\n        ]\n\n        return A.Compose(train_transforms), A.Compose(val_transforms)\n\n    def setup(self, stage=None):\n        images_train, images_val, masks_train, masks_val = train_test_split(self.all_images, self.all_masks, train_size=self.hparams.train_size_coef)\n        self.train_dataset = self.dataset(images_train, masks_train, self.train_transforms)\n        self.val_dataset = self.dataset(images_val, masks_val, self.val_transforms)\n\n    def train_dataloader(self):\n        return self._dataloader(self.train_dataset)\n\n    def val_dataloader(self):\n        return self._dataloader(self.val_dataset)\n\n    def _dataloader(self, dataset: RZDDataset) -> DataLoader:\n        return DataLoader(\n            dataset,\n            batch_size=self.hparams.batch_size,\n            num_workers=self.hparams.num_workers,\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:49.068366Z","iopub.execute_input":"2022-07-19T13:40:49.069308Z","iopub.status.idle":"2022-07-19T13:40:49.086670Z","shell.execute_reply.started":"2022-07-19T13:40:49.069253Z","shell.execute_reply":"2022-07-19T13:40:49.085647Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def show_batch():\n    nrows = 3\n    ncols = 3\n    batch_size = nrows * ncols\n    data_module = RZDDataModule(batch_size=batch_size)\n    data_module.setup()\n    data_loader = data_module.train_dataloader()\n\n    images, masks = next(iter(data_loader))\n\n    fig, _ = plt.subplots(figsize=(10, 10))\n    for i, (image, mask) in enumerate(zip(images, masks)):\n        plt.subplot(nrows, ncols, i + 1)\n        plt.tight_layout()\n        plt.axis('off')\n\n        image = image.permute(1, 2, 0).numpy()\n        mask = mask.numpy()\n\n        print(image.shape, image.min(), image.max(), image.mean(), image.std())\n        print(mask.shape, mask.min(), mask.max(), mask.mean(), mask.std())\n\n        plt.imshow(image)\n        plt.imshow(mask, alpha=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:50.471827Z","iopub.execute_input":"2022-07-19T13:40:50.472216Z","iopub.status.idle":"2022-07-19T13:40:50.486461Z","shell.execute_reply.started":"2022-07-19T13:40:50.472181Z","shell.execute_reply":"2022-07-19T13:40:50.483400Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"show_batch()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:40:51.411733Z","iopub.execute_input":"2022-07-19T13:40:51.412115Z","iopub.status.idle":"2022-07-19T13:41:19.431578Z","shell.execute_reply.started":"2022-07-19T13:40:51.412081Z","shell.execute_reply":"2022-07-19T13:41:19.430207Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def test_model_and_loss():\n    model = smp.UnetPlusPlus(\n                        encoder_name='resnet34', \n                        encoder_depth=5, \n                        encoder_weights=None,\n                        decoder_channels=(512, 256, 128, 64, 16),\n                        in_channels=3, \n                        classes=4, \n                        activation='sigmoid'\n                    )\n    data_module = RZDDataModule(batch_size=4)\n    data_module.setup()\n    data_loader = data_module.train_dataloader()\n    images, masks = next(iter(data_loader))\n    y_hat = model(images)\n    bce_loss = LOSS_FNS['bce']\n    dice_loss = LOSS_FNS['dice']\n    print(dice_loss(y_hat, masks.type(torch.int64)))","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:41:23.207187Z","iopub.execute_input":"2022-07-19T13:41:23.208265Z","iopub.status.idle":"2022-07-19T13:41:23.221295Z","shell.execute_reply.started":"2022-07-19T13:41:23.208208Z","shell.execute_reply":"2022-07-19T13:41:23.220014Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"test_model_and_loss()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:41:26.362998Z","iopub.execute_input":"2022-07-19T13:41:26.364323Z","iopub.status.idle":"2022-07-19T13:41:54.834489Z","shell.execute_reply.started":"2022-07-19T13:41:26.364266Z","shell.execute_reply":"2022-07-19T13:41:54.833297Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class RZDModel(pl.LightningModule):\n    def __init__(\n        self,\n        loss: str,\n        optimizer: str,\n        learning_rate: float,\n        weight_decay: float,\n        scheduler: str,\n        T_max: int,\n        T_0: int,\n        min_lr: int,\n    ):\n        super().__init__()\n\n        self.save_hyperparameters()\n\n        self.model = self._init_model()\n\n        self.loss_fn = self._init_loss_fn()\n\n#         self.metrics = self._init_metrics()\n\n    def _init_model(self) -> nn.Module:\n        return smp.UnetPlusPlus(\n                    encoder_name='resnet34', \n                    encoder_depth=5, \n                    encoder_weights=None,\n                    decoder_channels=(512, 256, 128, 64, 16),\n                    in_channels=3, \n                    classes=4, \n                    activation=None\n                )\n\n    def _init_loss_fn(self) -> Callable:\n        loss = self.hparams.loss\n        assert loss in LOSS_FNS, 'Choose from exstisting!'\n        return LOSS_FNS[loss]\n\n#     def _init_metrics(self) -> nn.ModuleDict:\n#         train_metrics = MetricCollection({\"train_dice\": Dice()})\n#         val_metrics = MetricCollection({\"val_dice\": Dice()})\n\n#         return nn.ModuleDict(\n#             {\n#                 \"train_metrics\": train_metrics,\n#                 \"val_metrics\": val_metrics,\n#             }\n#         )\n\n    def configure_optimizers(self) -> Dict[str, Any]:\n        optimizer_kwargs = dict(\n            params=self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay\n        )\n        if self.hparams.optimizer == \"Adam\":\n            optimizer = torch.optim.Adam(**optimizer_kwargs)\n        elif self.hparams.optimizer == \"AdamW\":\n            optimizer = torch.optim.AdamW(**optimizer_kwargs)\n        elif self.hparams.optimizer == \"SGD\":\n            optimizer = torch.optim.SGD(**optimizer_kwargs)\n        else:\n            raise ValueError(f\"Unknown optimizer: {self.hparams.optimizer}\")\n\n        if self.hparams.scheduler is not None:\n            if self.hparams.scheduler == \"CosineAnnealingLR\":\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n                    optimizer, T_max=self.hparams.T_max, eta_min=self.hparams.min_lr\n                )\n            elif self.hparams.scheduler == \"CosineAnnealingWarmRestarts\":\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                    optimizer, T_0=self.hparams.T_0, eta_min=self.hparams.min_lr\n                )\n            else:\n                raise ValueError(f\"Unknown scheduler: {self.hparams.scheduler}\")\n\n            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n        else:\n            return {\"optimizer\": optimizer}\n\n    def forward(self, images: torch.Tensor) -> torch.Tensor:\n        return self.model(images)\n\n    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n        return self.shared_step(batch, \"train\")\n\n    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n        self.shared_step(batch, \"val\")\n\n    def shared_step(self, batch: Tuple[torch.Tensor, torch.Tensor], stage: str) -> torch.Tensor:\n        images, masks = batch\n        y_pred = self(images)\n        \n        loss = self.loss_fn(y_pred, masks.type(torch.int64)) #error here\n#         metrics = self.metrics[f\"{stage}_metrics\"](y_pred, masks)\n\n        self._log(loss, metrics={}, stage=stage)\n\n        return loss\n\n    def _log(self, loss: torch.Tensor, metrics: dict, stage: str):\n        on_step = True if stage == \"train\" else False\n        self.log(f\"{stage}_loss\", loss)#, on_step=on_step, on_epoch=True, prog_bar=not on_step)\n#         self.log_dict(metrics, on_step=False, on_epoch=True)\n\n    @classmethod\n    def load_eval_checkpoint(cls, checkpoint_path: Path, device: str) -> nn.Module:\n        module = cls.load_from_checkpoint(checkpoint_path=checkpoint_path).to(device)\n        module.eval()\n\n        return module","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:42:02.570485Z","iopub.execute_input":"2022-07-19T13:42:02.570865Z","iopub.status.idle":"2022-07-19T13:42:02.598080Z","shell.execute_reply.started":"2022-07-19T13:42:02.570835Z","shell.execute_reply":"2022-07-19T13:42:02.596939Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def train():\n    pl.seed_everything(hash(\"kek\") % 2**32 - 1)\n    \n    model = RZDModel(LOSS, OPTIMIZER, LEARNING_RATE, WEIGHT_DECAY, SCHEDULER, 0, 0, MIN_LR)\n    data_module = RZDDataModule(batch_size=BATCH_SIZE)\n    trainer = pl.Trainer(\n        logger=wandb_logger,\n        max_epochs=MAX_EPOCHS,\n        fast_dev_run=FAST_DEV_RUN,\n        gpus=GPUS,\n        )\n    trainer.fit(model, data_module)\n    return trainer","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:42:03.754081Z","iopub.execute_input":"2022-07-19T13:42:03.755330Z","iopub.status.idle":"2022-07-19T13:42:03.770180Z","shell.execute_reply.started":"2022-07-19T13:42:03.755292Z","shell.execute_reply":"2022-07-19T13:42:03.769163Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:42:04.546309Z","iopub.execute_input":"2022-07-19T13:42:04.546975Z","iopub.status.idle":"2022-07-19T13:42:04.561584Z","shell.execute_reply.started":"2022-07-19T13:42:04.546933Z","shell.execute_reply":"2022-07-19T13:42:04.560418Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"trainer = train()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:42:07.598683Z","iopub.execute_input":"2022-07-19T13:42:07.599065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:39:29.326830Z","iopub.execute_input":"2022-07-19T13:39:29.327306Z","iopub.status.idle":"2022-07-19T13:39:30.220862Z","shell.execute_reply.started":"2022-07-19T13:39:29.327269Z","shell.execute_reply":"2022-07-19T13:39:30.219703Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}