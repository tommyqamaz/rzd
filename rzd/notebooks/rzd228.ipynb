{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2022-07-18T10:58:39.625387Z","iopub.execute_input":"2022-07-18T10:58:39.625780Z","iopub.status.idle":"2022-07-18T10:58:56.116520Z","shell.execute_reply.started":"2022-07-18T10:58:39.625747Z","shell.execute_reply":"2022-07-18T10:58:56.115357Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import Tuple, List\n\nimport albumentations as A\nimport cv2\nimport numpy as np\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport segmentation_models_pytorch as smp\nfrom albumentations.pytorch import ToTensorV2\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchmetrics import Dice\nfrom torchmetrics import MetricCollection","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:03:56.100315Z","iopub.execute_input":"2022-07-18T11:03:56.101180Z","iopub.status.idle":"2022-07-18T11:03:57.541864Z","shell.execute_reply.started":"2022-07-18T11:03:56.101135Z","shell.execute_reply":"2022-07-18T11:03:57.540444Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from os import path\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:03:57.543761Z","iopub.execute_input":"2022-07-18T11:03:57.544134Z","iopub.status.idle":"2022-07-18T11:03:57.549539Z","shell.execute_reply.started":"2022-07-18T11:03:57.544098Z","shell.execute_reply":"2022-07-18T11:03:57.548385Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"CLASSES = {7: 'railway', 6: 'other railways', 10: 'trains'}\nTRAIN_DATASET_PATH = '../input/train-dataset/train_dataset_train/train'\nTRAIN_PATH = {'images': path.join(TRAIN_DATASET_PATH, 'images'), 'mask': path.join(TRAIN_DATASET_PATH, 'mask')}\nALL_MASKS = glob.glob(path.join(TRAIN_PATH['mask'], '*.png'))\nALL_IMAGES = glob.glob(path.join(TRAIN_PATH['images'], '*.png'))","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:03:58.629123Z","iopub.execute_input":"2022-07-18T11:03:58.629519Z","iopub.status.idle":"2022-07-18T11:03:59.578290Z","shell.execute_reply.started":"2022-07-18T11:03:58.629487Z","shell.execute_reply":"2022-07-18T11:03:59.577225Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class RZDDataset(Dataset):\n    def __init__(self, image_paths: List[Path] = ALL_IMAGES, mask_paths: List[Path] = ALL_MASKS, transforms: Callable = None):        \n        self.image_paths = image_paths\n\n        self.mask_paths = mask_paths\n\n        self.transforms = transforms\n\n    def __len__(self) -> int:\n        return len(self.image_paths)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        image_path = self.image_paths[idx]\n        mask_path = self.mask_paths[idx]\n\n        image = self._load_image(image_path)\n        mask = self._load_mask(mask_path)\n        if self.transforms is not None:\n            data = self.transforms(image=image, mask=mask)\n            image, mask = data[\"image\"], data[\"mask\"]\n\n        return image, mask\n\n    @staticmethod\n    def _load_image(image_path: Path) -> np.ndarray:\n        return cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n\n    @staticmethod\n    def _load_mask(mask_path: Path) -> np.ndarray:\n        return cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:03:59.580081Z","iopub.execute_input":"2022-07-18T11:03:59.580913Z","iopub.status.idle":"2022-07-18T11:03:59.592327Z","shell.execute_reply.started":"2022-07-18T11:03:59.580871Z","shell.execute_reply":"2022-07-18T11:03:59.591080Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ds = RZDDataset()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:03:59.738796Z","iopub.execute_input":"2022-07-18T11:03:59.739214Z","iopub.status.idle":"2022-07-18T11:03:59.745376Z","shell.execute_reply.started":"2022-07-18T11:03:59.739178Z","shell.execute_reply":"2022-07-18T11:03:59.743857Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def show_examples(name: str, pair: np.array):\n    plt.figure(figsize=(10, 14))\n    plt.subplot(1, 2, 1)\n    plt.imshow(pair[1])\n    plt.title(f\"Image: {name}\")\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(pair[0])\n    plt.title(f\"Mask: {name}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:04:00.230674Z","iopub.execute_input":"2022-07-18T11:04:00.232031Z","iopub.status.idle":"2022-07-18T11:04:00.238729Z","shell.execute_reply.started":"2022-07-18T11:04:00.231959Z","shell.execute_reply":"2022-07-18T11:04:00.237372Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"show_examples('train', ds[34])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:04:09.656151Z","iopub.execute_input":"2022-07-18T11:04:09.656853Z","iopub.status.idle":"2022-07-18T11:04:10.488006Z","shell.execute_reply.started":"2022-07-18T11:04:09.656803Z","shell.execute_reply":"2022-07-18T11:04:10.486893Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"show_examples('train', ds[32])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:04:01.711592Z","iopub.execute_input":"2022-07-18T11:04:01.712355Z","iopub.status.idle":"2022-07-18T11:04:03.094353Z","shell.execute_reply.started":"2022-07-18T11:04:01.712319Z","shell.execute_reply":"2022-07-18T11:04:03.093066Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"show_examples('train', ds[123])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:04:03.096217Z","iopub.execute_input":"2022-07-18T11:04:03.096536Z","iopub.status.idle":"2022-07-18T11:04:03.914536Z","shell.execute_reply.started":"2022-07-18T11:04:03.096509Z","shell.execute_reply":"2022-07-18T11:04:03.913401Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class RZDDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        dataset = RZDDataset,\n        all_images: List[Path] = ALL_IMAGES,\n        all_masks: List[Path] = ALL_MASKS,\n        train_size_coef: int = 0.8,\n        batch_size: int = 8,\n        num_workers: int = 2,\n        input_shape: Tuple[int, int] = (512, 512)\n    ):\n        super().__init__()\n        \n        self.dataset = dataset\n        self.all_images = all_images\n        self.all_masks = all_masks\n        self.save_hyperparameters()\n\n        self.train_transforms, self.val_transforms = self._init_transforms()\n\n    def _init_transforms(self) -> Tuple[Callable, Callable]:\n        train_transforms = [\n            A.Resize(*self.hparams.input_shape),\n            A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n            ToTensorV2(),\n            \n        ]\n\n        val_transforms = [\n            A.Resize(*self.hparams.input_shape),\n            A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n            ToTensorV2(),\n        ]\n\n        return A.Compose(train_transforms), A.Compose(val_transforms)\n\n    def setup(self):\n        images_train, images_val, masks_train, masks_val = train_test_split(self.all_images, self.all_masks, train_size=self.hparams.train_size_coef)\n        self.train_dataset = self.dataset(images_train, masks_train, self.train_transforms)\n        self.val_dataset = self.dataset(images_val, masks_val, self.val_transforms)\n\n    def train_dataloader(self):\n        return self._dataloader(self.train_dataset)\n\n    def val_dataloader(self):\n        return self._dataloader(self.val_dataset)\n\n    def _dataloader(self, dataset: RZDDataset) -> DataLoader:\n        return DataLoader(\n            dataset,\n            batch_size=self.hparams.batch_size,\n            num_workers=self.hparams.num_workers,\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:25:34.269045Z","iopub.execute_input":"2022-07-18T11:25:34.269428Z","iopub.status.idle":"2022-07-18T11:25:34.284527Z","shell.execute_reply.started":"2022-07-18T11:25:34.269397Z","shell.execute_reply":"2022-07-18T11:25:34.282097Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def show_batch():\n    nrows = 3\n    ncols = 3\n    batch_size = nrows * ncols\n    data_module = RZDDataModule(batch_size=batch_size)\n    data_module.setup()\n    data_loader = data_module.train_dataloader()\n\n    images, masks = next(iter(data_loader))\n\n    fig, _ = plt.subplots(figsize=(10, 10))\n    for i, (image, mask) in enumerate(zip(images, masks)):\n        plt.subplot(nrows, ncols, i + 1)\n        plt.tight_layout()\n        plt.axis('off')\n\n        image = image.permute(1, 2, 0).numpy()\n        mask = mask.numpy()\n\n        print(image.shape, image.min(), image.max(), image.mean(), image.std())\n        print(mask.shape, mask.min(), mask.max(), mask.mean(), mask.std())\n\n        plt.imshow(image)\n        plt.imshow(mask, alpha=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:25:35.307759Z","iopub.execute_input":"2022-07-18T11:25:35.308594Z","iopub.status.idle":"2022-07-18T11:25:35.318626Z","shell.execute_reply.started":"2022-07-18T11:25:35.308543Z","shell.execute_reply":"2022-07-18T11:25:35.317214Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"show_batch()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:25:36.255581Z","iopub.execute_input":"2022-07-18T11:25:36.256012Z","iopub.status.idle":"2022-07-18T11:25:41.443542Z","shell.execute_reply.started":"2022-07-18T11:25:36.255953Z","shell.execute_reply":"2022-07-18T11:25:41.441876Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model = smp.UnetPlusPlus(\n    encoder_name='resnet34', \n    encoder_depth=5, \n    encoder_weights=None, \n    in_channels=3, \n    classes=len(CLASSES), \n    activation=\"softmax\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:21:51.387101Z","iopub.execute_input":"2022-07-18T11:21:51.387477Z","iopub.status.idle":"2022-07-18T11:21:51.876438Z","shell.execute_reply.started":"2022-07-18T11:21:51.387448Z","shell.execute_reply":"2022-07-18T11:21:51.875211Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"sample = torch.randn(1, 3, 512 * 2, 512 * 2)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:23:46.285348Z","iopub.execute_input":"2022-07-18T11:23:46.285736Z","iopub.status.idle":"2022-07-18T11:23:46.314791Z","shell.execute_reply.started":"2022-07-18T11:23:46.285707Z","shell.execute_reply":"2022-07-18T11:23:46.313655Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model(sample).shape","metadata":{"execution":{"iopub.status.busy":"2022-07-18T11:23:46.612923Z","iopub.execute_input":"2022-07-18T11:23:46.613325Z","iopub.status.idle":"2022-07-18T11:23:56.075682Z","shell.execute_reply.started":"2022-07-18T11:23:46.613293Z","shell.execute_reply":"2022-07-18T11:23:56.074468Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class RZDLitModule(pl.LightningModule):\n    LOSS_FNS = {\n        \"bce\": smp.losses.SoftBCEWithLogitsLoss(),\n        \"dice\": smp.losses.DiceLoss(mode=\"multiclass\"),\n        \"focal\": smp.losses.FocalLoss(mode=\"multiclass\"),\n        \"jaccard\": smp.losses.JaccardLoss(mode=\"multiclass\"),\n        \"lovasz\": smp.losses.LovaszLoss(mode=\"multiclass\"),\n        \"tversky\": smp.losses.TverskyLoss(mode=\"multiclass\"),\n    }\n\n    def __init__(\n        self,\n        arch: str,\n        encoder_name: str,\n        encoder_weights: str,\n        loss: str,\n        optimizer: str,\n        learning_rate: float,\n        weight_decay: float,\n        scheduler: str,\n        T_max: int,\n        T_0: int,\n        min_lr: int,\n    ):\n        super().__init__()\n\n        self.save_hyperparameters()\n\n        self.model = self._init_model()\n\n        self.loss_fn = self._init_loss_fn()\n\n        self.metrics = self._init_metrics()\n\n    def _init_model(self) -> nn.Module:\n        return smp.create_model(\n            self.hparams.arch,\n            encoder_name=self.hparams.encoder_name,\n            encoder_weights=self.hparams.encoder_weights,\n            classes=1,\n            activation=\"sigmoid\",\n        )\n\n    def _init_loss_fn(self) -> Callable:\n        losses = self.hparams.loss.split(\"_\")\n        loss_fns = [self.LOSS_FNS[loss] for loss in losses]\n\n        def criterion(y_pred, y_true):\n            return sum(loss_fn(y_pred, y_true) for loss_fn in loss_fns) / len(loss_fns)\n\n        return criterion\n\n    def _init_metrics(self) -> nn.ModuleDict:\n        train_metrics = MetricCollection({\"train_dice\": Dice()})\n        val_metrics = MetricCollection({\"val_dice\": Dice()})\n\n        return nn.ModuleDict(\n            {\n                \"train_metrics\": train_metrics,\n                \"val_metrics\": val_metrics,\n            }\n        )\n\n    def configure_optimizers(self) -> Dict[str, Any]:\n        optimizer_kwargs = dict(\n            params=self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay\n        )\n        if self.hparams.optimizer == \"Adam\":\n            optimizer = torch.optim.Adam(**optimizer_kwargs)\n        elif self.hparams.optimizer == \"AdamW\":\n            optimizer = torch.optim.AdamW(**optimizer_kwargs)\n        elif self.hparams.optimizer == \"SGD\":\n            optimizer = torch.optim.SGD(**optimizer_kwargs)\n        else:\n            raise ValueError(f\"Unknown optimizer: {self.hparams.optimizer}\")\n\n        if self.hparams.scheduler is not None:\n            if self.hparams.scheduler == \"CosineAnnealingLR\":\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n                    optimizer, T_max=self.hparams.T_max, eta_min=self.hparams.min_lr\n                )\n            elif self.hparams.scheduler == \"CosineAnnealingWarmRestarts\":\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                    optimizer, T_0=self.hparams.T_0, eta_min=self.hparams.min_lr\n                )\n            else:\n                raise ValueError(f\"Unknown scheduler: {self.hparams.scheduler}\")\n\n            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n        else:\n            return {\"optimizer\": optimizer}\n\n    def forward(self, images: torch.Tensor) -> torch.Tensor:\n        return self.model(images)\n\n    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n        return self.shared_step(batch, \"train\")\n\n    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n        self.shared_step(batch, \"val\")\n\n    def shared_step(self, batch: Tuple[torch.Tensor, torch.Tensor], stage: str) -> torch.Tensor:\n        images, masks = batch\n        y_pred = self(images)\n\n        loss = self.loss_fn(y_pred, masks)\n        metrics = self.metrics[f\"{stage}_metrics\"](y_pred, masks)\n\n        self._log(loss, metrics, stage)\n\n        return loss\n\n    def _log(self, loss: torch.Tensor, metrics: dict, stage: str):\n        on_step = True if stage == \"train\" else False\n        self.log(f\"{stage}_loss\", loss, on_step=on_step, on_epoch=True, prog_bar=not on_step)\n        self.log_dict(metrics, on_step=False, on_epoch=True)\n\n    @classmethod\n    def load_eval_checkpoint(cls, checkpoint_path: Path, device: str) -> nn.Module:\n        module = cls.load_from_checkpoint(checkpoint_path=checkpoint_path).to(device)\n        module.eval()\n\n        return module","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RZDLitModule(pl.LightningModule):\n    LOSS_FNS = {\n        \"bce\": smp.losses.SoftBCEWithLogitsLoss(),\n        \"dice\": smp.losses.DiceLoss(mode=\"multiclass\"),\n        \"focal\": smp.losses.FocalLoss(mode=\"multiclass\"),\n        \"jaccard\": smp.losses.JaccardLoss(mode=\"multiclass\"),\n        \"lovasz\": smp.losses.LovaszLoss(mode=\"multiclass\"),\n        \"tversky\": smp.losses.TverskyLoss(mode=\"multiclass\"),\n    }\n\n    def __init__(\n        self,\n        arch: str,\n        encoder_name: str,\n        encoder_weights: str,\n        loss: str,\n        optimizer: str,\n        learning_rate: float,\n        weight_decay: float,\n        scheduler: str,\n        T_max: int,\n        T_0: int,\n        min_lr: int,\n    ):\n        super().__init__()\n\n        self.save_hyperparameters()\n\n        self.model = self._init_model()\n\n        self.loss_fn = self._init_loss_fn()\n\n        self.metrics = self._init_metrics()\n\n    def _init_model(self) -> nn.Module:\n        return smp.create_model(\n            self.hparams.arch,\n            encoder_name=self.hparams.encoder_name,\n            encoder_weights=self.hparams.encoder_weights,\n            classes=1,\n            activation=\"sigmoid\",\n        )\n\n    def _init_loss_fn(self) -> Callable:\n        losses = self.hparams.loss.split(\"_\")\n        loss_fns = [self.LOSS_FNS[loss] for loss in losses]\n\n        def criterion(y_pred, y_true):\n            return sum(loss_fn(y_pred, y_true) for loss_fn in loss_fns) / len(loss_fns)\n\n        return criterion\n\n    def _init_metrics(self) -> nn.ModuleDict:\n        train_metrics = MetricCollection({\"train_dice\": Dice()})\n        val_metrics = MetricCollection({\"val_dice\": Dice()})\n\n        return nn.ModuleDict(\n            {\n                \"train_metrics\": train_metrics,\n                \"val_metrics\": val_metrics,\n            }\n        )\n\n    def configure_optimizers(self) -> Dict[str, Any]:\n        optimizer_kwargs = dict(\n            params=self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay\n        )\n        if self.hparams.optimizer == \"Adam\":\n            optimizer = torch.optim.Adam(**optimizer_kwargs)\n        elif self.hparams.optimizer == \"AdamW\":\n            optimizer = torch.optim.AdamW(**optimizer_kwargs)\n        elif self.hparams.optimizer == \"SGD\":\n            optimizer = torch.optim.SGD(**optimizer_kwargs)\n        else:\n            raise ValueError(f\"Unknown optimizer: {self.hparams.optimizer}\")\n\n        if self.hparams.scheduler is not None:\n            if self.hparams.scheduler == \"CosineAnnealingLR\":\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n                    optimizer, T_max=self.hparams.T_max, eta_min=self.hparams.min_lr\n                )\n            elif self.hparams.scheduler == \"CosineAnnealingWarmRestarts\":\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                    optimizer, T_0=self.hparams.T_0, eta_min=self.hparams.min_lr\n                )\n            else:\n                raise ValueError(f\"Unknown scheduler: {self.hparams.scheduler}\")\n\n            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n        else:\n            return {\"optimizer\": optimizer}\n\n    def forward(self, images: torch.Tensor) -> torch.Tensor:\n        return self.model(images)\n\n    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n        return self.shared_step(batch, \"train\")\n\n    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n        self.shared_step(batch, \"val\")\n\n    def shared_step(self, batch: Tuple[torch.Tensor, torch.Tensor], stage: str) -> torch.Tensor:\n        images, masks = batch\n        y_pred = self(images)\n\n        loss = self.loss_fn(y_pred, masks)\n        metrics = self.metrics[f\"{stage}_metrics\"](y_pred, masks)\n\n        self._log(loss, metrics, stage)\n\n        return loss\n\n    def _log(self, loss: torch.Tensor, metrics: dict, stage: str):\n        on_step = True if stage == \"train\" else False\n        self.log(f\"{stage}_loss\", loss, on_step=on_step, on_epoch=True, prog_bar=not on_step)\n        self.log_dict(metrics, on_step=False, on_epoch=True)\n\n    @classmethod\n    def load_eval_checkpoint(cls, checkpoint_path: Path, device: str) -> nn.Module:\n        module = cls.load_from_checkpoint(checkpoint_path=checkpoint_path).to(device)\n        module.eval()\n\n        return module","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}