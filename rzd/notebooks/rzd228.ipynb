{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T10:58:39.625780Z","iopub.status.busy":"2022-07-18T10:58:39.625387Z","iopub.status.idle":"2022-07-18T10:58:56.116520Z","shell.execute_reply":"2022-07-18T10:58:56.115357Z","shell.execute_reply.started":"2022-07-18T10:58:39.625747Z"},"trusted":true},"outputs":[],"source":["! pip install segmentation_models_pytorch"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:03:56.101180Z","iopub.status.busy":"2022-07-18T11:03:56.100315Z","iopub.status.idle":"2022-07-18T11:03:57.541864Z","shell.execute_reply":"2022-07-18T11:03:57.540444Z","shell.execute_reply.started":"2022-07-18T11:03:56.101135Z"},"trusted":true},"outputs":[],"source":["from pathlib import Path\n","from typing import Any\n","from typing import Callable\n","from typing import Dict\n","from typing import Tuple, List\n","\n","import albumentations as A\n","import cv2\n","import numpy as np\n","import pytorch_lightning as pl\n","import torch\n","import torch.nn as nn\n","import segmentation_models_pytorch as smp\n","from albumentations.pytorch import ToTensorV2\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import StratifiedKFold\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torchmetrics import Dice\n","from torchmetrics import MetricCollection\n","from os import path\n","import glob\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:03:58.629519Z","iopub.status.busy":"2022-07-18T11:03:58.629123Z","iopub.status.idle":"2022-07-18T11:03:59.578290Z","shell.execute_reply":"2022-07-18T11:03:59.577225Z","shell.execute_reply.started":"2022-07-18T11:03:58.629487Z"},"trusted":true},"outputs":[],"source":["CLASSES = {7: 'railway', 6: 'other railways', 10: 'trains'}\n","TRAIN_DATASET_PATH = '../input/train-dataset/train_dataset_train/train'\n","TRAIN_PATH = {'images': path.join(TRAIN_DATASET_PATH, 'images'), 'mask': path.join(TRAIN_DATASET_PATH, 'mask')}\n","ALL_MASKS = glob.glob(path.join(TRAIN_PATH['mask'], '*.png'))\n","ALL_IMAGES = glob.glob(path.join(TRAIN_PATH['images'], '*.png'))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:03:59.580913Z","iopub.status.busy":"2022-07-18T11:03:59.580081Z","iopub.status.idle":"2022-07-18T11:03:59.592327Z","shell.execute_reply":"2022-07-18T11:03:59.591080Z","shell.execute_reply.started":"2022-07-18T11:03:59.580871Z"},"trusted":true},"outputs":[],"source":["class RZDDataset(Dataset):\n","    def __init__(self, image_paths: List[Path] = ALL_IMAGES, mask_paths: List[Path] = ALL_MASKS, transforms: Callable = None):        \n","        self.image_paths = image_paths\n","\n","        self.mask_paths = mask_paths\n","\n","        self.transforms = transforms\n","\n","    def __len__(self) -> int:\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n","        image_path = self.image_paths[idx]\n","        mask_path = self.mask_paths[idx]\n","\n","        image = self._load_image(image_path)\n","        mask = self._load_mask(mask_path)\n","        if self.transforms is not None:\n","            data = self.transforms(image=image, mask=mask)\n","            image, mask = data[\"image\"], data[\"mask\"]\n","\n","        return image, mask\n","\n","    @staticmethod\n","    def _load_image(image_path: Path) -> np.ndarray:\n","        return cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n","\n","    @staticmethod\n","    def _load_mask(mask_path: Path) -> np.ndarray:\n","        return cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:03:59.739214Z","iopub.status.busy":"2022-07-18T11:03:59.738796Z","iopub.status.idle":"2022-07-18T11:03:59.745376Z","shell.execute_reply":"2022-07-18T11:03:59.743857Z","shell.execute_reply.started":"2022-07-18T11:03:59.739178Z"},"trusted":true},"outputs":[],"source":["ds = RZDDataset()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:04:00.232031Z","iopub.status.busy":"2022-07-18T11:04:00.230674Z","iopub.status.idle":"2022-07-18T11:04:00.238729Z","shell.execute_reply":"2022-07-18T11:04:00.237372Z","shell.execute_reply.started":"2022-07-18T11:04:00.231959Z"},"trusted":true},"outputs":[],"source":["def show_examples(name: str, pair: np.array):\n","    plt.figure(figsize=(10, 14))\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(pair[1])\n","    plt.title(f\"Image: {name}\")\n","\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(pair[0])\n","    plt.title(f\"Mask: {name}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:04:09.656853Z","iopub.status.busy":"2022-07-18T11:04:09.656151Z","iopub.status.idle":"2022-07-18T11:04:10.488006Z","shell.execute_reply":"2022-07-18T11:04:10.486893Z","shell.execute_reply.started":"2022-07-18T11:04:09.656803Z"},"trusted":true},"outputs":[],"source":["show_examples('train', ds[34])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:04:01.712355Z","iopub.status.busy":"2022-07-18T11:04:01.711592Z","iopub.status.idle":"2022-07-18T11:04:03.094353Z","shell.execute_reply":"2022-07-18T11:04:03.093066Z","shell.execute_reply.started":"2022-07-18T11:04:01.712319Z"},"trusted":true},"outputs":[],"source":["show_examples('train', ds[32])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:04:03.096536Z","iopub.status.busy":"2022-07-18T11:04:03.096217Z","iopub.status.idle":"2022-07-18T11:04:03.914536Z","shell.execute_reply":"2022-07-18T11:04:03.913401Z","shell.execute_reply.started":"2022-07-18T11:04:03.096509Z"},"trusted":true},"outputs":[],"source":["show_examples('train', ds[123])"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:25:34.269428Z","iopub.status.busy":"2022-07-18T11:25:34.269045Z","iopub.status.idle":"2022-07-18T11:25:34.284527Z","shell.execute_reply":"2022-07-18T11:25:34.282097Z","shell.execute_reply.started":"2022-07-18T11:25:34.269397Z"},"trusted":true},"outputs":[],"source":["class RZDDataModule(pl.LightningDataModule):\n","    def __init__(\n","        self,\n","        dataset = RZDDataset,\n","        all_images: List[Path] = ALL_IMAGES,\n","        all_masks: List[Path] = ALL_MASKS,\n","        train_size_coef: int = 0.8,\n","        batch_size: int = 8,\n","        num_workers: int = 2,\n","        input_shape: Tuple[int, int] = (512, 512)\n","    ):\n","        super().__init__()\n","        \n","        self.dataset = dataset\n","        self.all_images = all_images\n","        self.all_masks = all_masks\n","        self.save_hyperparameters()\n","\n","        self.train_transforms, self.val_transforms = self._init_transforms()\n","\n","    def _init_transforms(self) -> Tuple[Callable, Callable]:\n","        train_transforms = [\n","            A.Resize(*self.hparams.input_shape),\n","            A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","            ToTensorV2(),\n","            \n","        ]\n","\n","        val_transforms = [\n","            A.Resize(*self.hparams.input_shape),\n","            A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","            ToTensorV2(),\n","        ]\n","\n","        return A.Compose(train_transforms), A.Compose(val_transforms)\n","\n","    def setup(self):\n","        images_train, images_val, masks_train, masks_val = train_test_split(self.all_images, self.all_masks, train_size=self.hparams.train_size_coef)\n","        self.train_dataset = self.dataset(images_train, masks_train, self.train_transforms)\n","        self.val_dataset = self.dataset(images_val, masks_val, self.val_transforms)\n","\n","    def train_dataloader(self):\n","        return self._dataloader(self.train_dataset)\n","\n","    def val_dataloader(self):\n","        return self._dataloader(self.val_dataset)\n","\n","    def _dataloader(self, dataset: RZDDataset) -> DataLoader:\n","        return DataLoader(\n","            dataset,\n","            batch_size=self.hparams.batch_size,\n","            num_workers=self.hparams.num_workers,\n","        )"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:25:35.308594Z","iopub.status.busy":"2022-07-18T11:25:35.307759Z","iopub.status.idle":"2022-07-18T11:25:35.318626Z","shell.execute_reply":"2022-07-18T11:25:35.317214Z","shell.execute_reply.started":"2022-07-18T11:25:35.308543Z"},"trusted":true},"outputs":[],"source":["def show_batch():\n","    nrows = 3\n","    ncols = 3\n","    batch_size = nrows * ncols\n","    data_module = RZDDataModule(batch_size=batch_size)\n","    data_module.setup()\n","    data_loader = data_module.train_dataloader()\n","\n","    images, masks = next(iter(data_loader))\n","\n","    fig, _ = plt.subplots(figsize=(10, 10))\n","    for i, (image, mask) in enumerate(zip(images, masks)):\n","        plt.subplot(nrows, ncols, i + 1)\n","        plt.tight_layout()\n","        plt.axis('off')\n","\n","        image = image.permute(1, 2, 0).numpy()\n","        mask = mask.numpy()\n","\n","        print(image.shape, image.min(), image.max(), image.mean(), image.std())\n","        print(mask.shape, mask.min(), mask.max(), mask.mean(), mask.std())\n","\n","        plt.imshow(image)\n","        plt.imshow(mask, alpha=0.2)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:25:36.256012Z","iopub.status.busy":"2022-07-18T11:25:36.255581Z","iopub.status.idle":"2022-07-18T11:25:41.443542Z","shell.execute_reply":"2022-07-18T11:25:41.441876Z","shell.execute_reply.started":"2022-07-18T11:25:36.255953Z"},"trusted":true},"outputs":[],"source":["show_batch()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:21:51.387477Z","iopub.status.busy":"2022-07-18T11:21:51.387101Z","iopub.status.idle":"2022-07-18T11:21:51.876438Z","shell.execute_reply":"2022-07-18T11:21:51.875211Z","shell.execute_reply.started":"2022-07-18T11:21:51.387448Z"},"trusted":true},"outputs":[],"source":["model = smp.UnetPlusPlus(\n","    encoder_name='resnet34', \n","    encoder_depth=5, \n","    encoder_weights=None, \n","    in_channels=3, \n","    classes=len(CLASSES), \n","    activation=\"softmax\"\n",")"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:23:46.285736Z","iopub.status.busy":"2022-07-18T11:23:46.285348Z","iopub.status.idle":"2022-07-18T11:23:46.314791Z","shell.execute_reply":"2022-07-18T11:23:46.313655Z","shell.execute_reply.started":"2022-07-18T11:23:46.285707Z"},"trusted":true},"outputs":[],"source":["sample = torch.randn(1, 3, 512 * 2, 512 * 2)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-07-18T11:23:46.613325Z","iopub.status.busy":"2022-07-18T11:23:46.612923Z","iopub.status.idle":"2022-07-18T11:23:56.075682Z","shell.execute_reply":"2022-07-18T11:23:56.074468Z","shell.execute_reply.started":"2022-07-18T11:23:46.613293Z"},"trusted":true},"outputs":[],"source":["model(sample).shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class RZDLitModule(pl.LightningModule):\n","    LOSS_FNS = {\n","        \"bce\": smp.losses.SoftBCEWithLogitsLoss(),\n","        \"dice\": smp.losses.DiceLoss(mode=\"multiclass\"),\n","        \"focal\": smp.losses.FocalLoss(mode=\"multiclass\"),\n","        \"jaccard\": smp.losses.JaccardLoss(mode=\"multiclass\"),\n","        \"lovasz\": smp.losses.LovaszLoss(mode=\"multiclass\"),\n","        \"tversky\": smp.losses.TverskyLoss(mode=\"multiclass\"),\n","    }\n","\n","    def __init__(\n","        self,\n","        encoder_name: str,\n","        encoder_weights: str,\n","        loss: str,\n","        optimizer: str,\n","        learning_rate: float,\n","        weight_decay: float,\n","        scheduler: str,\n","        T_max: int,\n","        T_0: int,\n","        min_lr: int,\n","    ):\n","        super().__init__()\n","\n","        self.save_hyperparameters()\n","\n","        self.model = self._init_model()\n","\n","        self.loss_fn = self._init_loss_fn()\n","\n","        self.metrics = self._init_metrics()\n","\n","    def _init_model(self) -> nn.Module:\n","        return smp.create_model(\n","            self.hparams.arch,\n","            encoder_name=self.hparams.encoder_name,\n","            encoder_weights=self.hparams.encoder_weights,\n","            classes=1,\n","            activation=\"sigmoid\",\n","        )\n","\n","    def _init_loss_fn(self) -> Callable:\n","        losses = self.hparams.loss.split(\"_\")\n","        loss_fns = [self.LOSS_FNS[loss] for loss in losses]\n","\n","        def criterion(y_pred, y_true):\n","            return sum(loss_fn(y_pred, y_true) for loss_fn in loss_fns) / len(loss_fns)\n","\n","        return criterion\n","\n","    def _init_metrics(self) -> nn.ModuleDict:\n","        train_metrics = MetricCollection({\"train_dice\": Dice()})\n","        val_metrics = MetricCollection({\"val_dice\": Dice()})\n","\n","        return nn.ModuleDict(\n","            {\n","                \"train_metrics\": train_metrics,\n","                \"val_metrics\": val_metrics,\n","            }\n","        )\n","\n","    def configure_optimizers(self) -> Dict[str, Any]:\n","        optimizer_kwargs = dict(\n","            params=self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay\n","        )\n","        if self.hparams.optimizer == \"Adam\":\n","            optimizer = torch.optim.Adam(**optimizer_kwargs)\n","        elif self.hparams.optimizer == \"AdamW\":\n","            optimizer = torch.optim.AdamW(**optimizer_kwargs)\n","        elif self.hparams.optimizer == \"SGD\":\n","            optimizer = torch.optim.SGD(**optimizer_kwargs)\n","        else:\n","            raise ValueError(f\"Unknown optimizer: {self.hparams.optimizer}\")\n","\n","        if self.hparams.scheduler is not None:\n","            if self.hparams.scheduler == \"CosineAnnealingLR\":\n","                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n","                    optimizer, T_max=self.hparams.T_max, eta_min=self.hparams.min_lr\n","                )\n","            elif self.hparams.scheduler == \"CosineAnnealingWarmRestarts\":\n","                scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","                    optimizer, T_0=self.hparams.T_0, eta_min=self.hparams.min_lr\n","                )\n","            else:\n","                raise ValueError(f\"Unknown scheduler: {self.hparams.scheduler}\")\n","\n","            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n","        else:\n","            return {\"optimizer\": optimizer}\n","\n","    def forward(self, images: torch.Tensor) -> torch.Tensor:\n","        return self.model(images)\n","\n","    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n","        return self.shared_step(batch, \"train\")\n","\n","    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n","        self.shared_step(batch, \"val\")\n","\n","    def shared_step(self, batch: Tuple[torch.Tensor, torch.Tensor], stage: str) -> torch.Tensor:\n","        images, masks = batch\n","        y_pred = self(images)\n","\n","        loss = self.loss_fn(y_pred, masks)\n","        metrics = self.metrics[f\"{stage}_metrics\"](y_pred, masks)\n","\n","        self._log(loss, metrics, stage)\n","\n","        return loss\n","\n","    def _log(self, loss: torch.Tensor, metrics: dict, stage: str):\n","        on_step = True if stage == \"train\" else False\n","        self.log(f\"{stage}_loss\", loss, on_step=on_step, on_epoch=True, prog_bar=not on_step)\n","        self.log_dict(metrics, on_step=False, on_epoch=True)\n","\n","    @classmethod\n","    def load_eval_checkpoint(cls, checkpoint_path: Path, device: str) -> nn.Module:\n","        module = cls.load_from_checkpoint(checkpoint_path=checkpoint_path).to(device)\n","        module.eval()\n","\n","        return module"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class RZDLitModule(pl.LightningModule):\n","    LOSS_FNS = {\n","        \"bce\": smp.losses.SoftBCEWithLogitsLoss(),\n","        \"dice\": smp.losses.DiceLoss(mode=\"multiclass\"),\n","        \"focal\": smp.losses.FocalLoss(mode=\"multiclass\"),\n","        \"jaccard\": smp.losses.JaccardLoss(mode=\"multiclass\"),\n","        \"lovasz\": smp.losses.LovaszLoss(mode=\"multiclass\"),\n","        \"tversky\": smp.losses.TverskyLoss(mode=\"multiclass\"),\n","    }\n","\n","    def __init__(\n","        self,\n","        arch: str,\n","        encoder_name: str,\n","        encoder_weights: str,\n","        loss: str,\n","        optimizer: str,\n","        learning_rate: float,\n","        weight_decay: float,\n","        scheduler: str,\n","        T_max: int,\n","        T_0: int,\n","        min_lr: int,\n","    ):\n","        super().__init__()\n","\n","        self.save_hyperparameters()\n","\n","        self.model = self._init_model()\n","\n","        self.loss_fn = self._init_loss_fn()\n","\n","        self.metrics = self._init_metrics()\n","\n","    def _init_model(self) -> nn.Module:\n","        return smp.create_model(\n","            self.hparams.arch,\n","            encoder_name=self.hparams.encoder_name,\n","            encoder_weights=self.hparams.encoder_weights,\n","            classes=1,\n","            activation=\"sigmoid\",\n","        )\n","\n","    def _init_loss_fn(self) -> Callable:\n","        losses = self.hparams.loss.split(\"_\")\n","        loss_fns = [self.LOSS_FNS[loss] for loss in losses]\n","\n","        def criterion(y_pred, y_true):\n","            return sum(loss_fn(y_pred, y_true) for loss_fn in loss_fns) / len(loss_fns)\n","\n","        return criterion\n","\n","    def _init_metrics(self) -> nn.ModuleDict:\n","        train_metrics = MetricCollection({\"train_dice\": Dice()})\n","        val_metrics = MetricCollection({\"val_dice\": Dice()})\n","\n","        return nn.ModuleDict(\n","            {\n","                \"train_metrics\": train_metrics,\n","                \"val_metrics\": val_metrics,\n","            }\n","        )\n","\n","    def configure_optimizers(self) -> Dict[str, Any]:\n","        optimizer_kwargs = dict(\n","            params=self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay\n","        )\n","        if self.hparams.optimizer == \"Adam\":\n","            optimizer = torch.optim.Adam(**optimizer_kwargs)\n","        elif self.hparams.optimizer == \"AdamW\":\n","            optimizer = torch.optim.AdamW(**optimizer_kwargs)\n","        elif self.hparams.optimizer == \"SGD\":\n","            optimizer = torch.optim.SGD(**optimizer_kwargs)\n","        else:\n","            raise ValueError(f\"Unknown optimizer: {self.hparams.optimizer}\")\n","\n","        if self.hparams.scheduler is not None:\n","            if self.hparams.scheduler == \"CosineAnnealingLR\":\n","                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n","                    optimizer, T_max=self.hparams.T_max, eta_min=self.hparams.min_lr\n","                )\n","            elif self.hparams.scheduler == \"CosineAnnealingWarmRestarts\":\n","                scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","                    optimizer, T_0=self.hparams.T_0, eta_min=self.hparams.min_lr\n","                )\n","            else:\n","                raise ValueError(f\"Unknown scheduler: {self.hparams.scheduler}\")\n","\n","            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n","        else:\n","            return {\"optimizer\": optimizer}\n","\n","    def forward(self, images: torch.Tensor) -> torch.Tensor:\n","        return self.model(images)\n","\n","    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n","        return self.shared_step(batch, \"train\")\n","\n","    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n","        self.shared_step(batch, \"val\")\n","\n","    def shared_step(self, batch: Tuple[torch.Tensor, torch.Tensor], stage: str) -> torch.Tensor:\n","        images, masks = batch\n","        y_pred = self(images)\n","\n","        loss = self.loss_fn(y_pred, masks)\n","        metrics = self.metrics[f\"{stage}_metrics\"](y_pred, masks)\n","\n","        self._log(loss, metrics, stage)\n","\n","        return loss\n","\n","    def _log(self, loss: torch.Tensor, metrics: dict, stage: str):\n","        on_step = True if stage == \"train\" else False\n","        self.log(f\"{stage}_loss\", loss, on_step=on_step, on_epoch=True, prog_bar=not on_step)\n","        self.log_dict(metrics, on_step=False, on_epoch=True)\n","\n","    @classmethod\n","    def load_eval_checkpoint(cls, checkpoint_path: Path, device: str) -> nn.Module:\n","        module = cls.load_from_checkpoint(checkpoint_path=checkpoint_path).to(device)\n","        module.eval()\n","\n","        return module"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 ('ganbot-fDLS-FpS-py3.8')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"ed481941dfd03a65c29d2f7939fa677f592bff1dd0b29e2e6d861e1497118507"}}},"nbformat":4,"nbformat_minor":4}
