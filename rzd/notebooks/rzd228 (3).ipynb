{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:18:59.446420Z","iopub.execute_input":"2022-07-20T07:18:59.447718Z","iopub.status.idle":"2022-07-20T07:19:16.517663Z","shell.execute_reply.started":"2022-07-20T07:18:59.447662Z","shell.execute_reply":"2022-07-20T07:19:16.516725Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from os import path\nimport glob\nimport os\nimport cv2\nimport shutil\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport segmentation_models_pytorch as smp\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchmetrics import Dice\nfrom torchmetrics import MetricCollection\n\nimport wandb\nfrom pytorch_lightning.loggers import WandbLogger\n\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import Tuple, List","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:20:05.877329Z","iopub.execute_input":"2022-07-20T07:20:05.877721Z","iopub.status.idle":"2022-07-20T07:20:07.285587Z","shell.execute_reply.started":"2022-07-20T07:20:05.877691Z","shell.execute_reply":"2022-07-20T07:20:07.284362Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"wandb_logger = WandbLogger(project=\"RZD\", name=\"v0_unetpp\", log_model=\"all\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\nNUM_WORKERS = 8\nLOSS = \"dice\"\nOPTIMIZER = \"Adam\"\nLEARNING_RATE = 3e-4\nWEIGHT_DECAY = 1e-6\nSCHEDULER = None\nMIN_LR = 1e-6\n\nFAST_DEV_RUN = False # Debug training\nGPUS = 1\nMAX_EPOCHS = 3\n\nCLASSES = {0:'background', 7: 'railway', 6: 'other railways', 10: 'trains'}\nMAP_MASKS = {7: 1, 6: 2, 10: 3, 0: 0}\nMAP_SUBMIT = {1: 7, 2: 6, 3: 10, 0: 0}\n\nTRAIN_DATASET_PATH = '../input/train-dataset/train_dataset_train/train'\nTRAIN_PATH = {'images': path.join(TRAIN_DATASET_PATH, 'images'), 'mask': path.join(TRAIN_DATASET_PATH, 'mask')}\nALL_MASKS = glob.glob(path.join(TRAIN_PATH['mask'], '*.png'))\nALL_IMAGES = glob.glob(path.join(TRAIN_PATH['images'], '*.png'))\n\nPATH_TEST = '../input/train-dataset/test_dataset_test'\nTEST_IMAGES = glob.glob(path.join(PATH_TEST, '*.png'))\n\n\nLOSS_FNS = {\n    \"bce\": smp.losses.SoftBCEWithLogitsLoss(),\n    \"dice\": smp.losses.DiceLoss(mode=\"multiclass\"),\n    \"focal\": smp.losses.FocalLoss(mode=\"multiclass\"),\n    \"jaccard\": smp.losses.JaccardLoss(mode=\"multiclass\"),\n    \"lovasz\": smp.losses.LovaszLoss(mode=\"multiclass\"),\n    \"tversky\": smp.losses.TverskyLoss(mode=\"multiclass\"),}","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:20:11.805027Z","iopub.execute_input":"2022-07-20T07:20:11.805430Z","iopub.status.idle":"2022-07-20T07:20:11.812334Z","shell.execute_reply.started":"2022-07-20T07:20:11.805398Z","shell.execute_reply":"2022-07-20T07:20:11.811421Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class RZDDataset(Dataset):\n    def __init__(self, image_paths: List[Path] = ALL_IMAGES, mask_paths: List[Path] = ALL_MASKS, transforms: Callable = None):        \n        self.image_paths = image_paths\n\n        self.mask_paths = mask_paths\n\n        self.transforms = transforms\n\n    def __len__(self) -> int:\n        return len(self.image_paths)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        image_path = self.image_paths[idx]\n        mask_path = self.mask_paths[idx]\n\n        image = self._load_image(image_path)\n        mask = self._load_mask(mask_path)\n        if self.transforms is not None:\n            data = self.transforms(image=image, mask=mask)\n            image, mask = data[\"image\"], data[\"mask\"]\n\n        return image, mask\n\n    @staticmethod\n    def _load_image(image_path: Path) -> np.ndarray:\n        return cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n\n    @staticmethod\n    def _load_mask(mask_path: Path) -> np.ndarray:\n        transorm_mask = np.vectorize(lambda x: MAP_MASKS[x])\n        return transorm_mask(cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:20:13.086517Z","iopub.execute_input":"2022-07-20T07:20:13.086797Z","iopub.status.idle":"2022-07-20T07:20:13.098077Z","shell.execute_reply.started":"2022-07-20T07:20:13.086770Z","shell.execute_reply":"2022-07-20T07:20:13.096942Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"ds = RZDDataset()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:20:14.184089Z","iopub.execute_input":"2022-07-20T07:20:14.185189Z","iopub.status.idle":"2022-07-20T07:20:14.190526Z","shell.execute_reply.started":"2022-07-20T07:20:14.185130Z","shell.execute_reply":"2022-07-20T07:20:14.189305Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def show_examples(name: str, pair: np.array):\n    plt.figure(figsize=(10, 14))\n    plt.subplot(1, 2, 1)\n    plt.imshow(pair[1])\n    plt.title(f\"Image: {name}\")\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(pair[0])\n    plt.title(f\"Mask: {name}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:20:20.617311Z","iopub.execute_input":"2022-07-20T07:20:20.618027Z","iopub.status.idle":"2022-07-20T07:20:20.625171Z","shell.execute_reply.started":"2022-07-20T07:20:20.617979Z","shell.execute_reply":"2022-07-20T07:20:20.624088Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"show_examples('train', ds[34])","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:20:22.703251Z","iopub.execute_input":"2022-07-20T07:20:22.703934Z","iopub.status.idle":"2022-07-20T07:20:24.212196Z","shell.execute_reply.started":"2022-07-20T07:20:22.703879Z","shell.execute_reply":"2022-07-20T07:20:24.211406Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class RZDDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        dataset = RZDDataset,\n        all_images: List[Path] = ALL_IMAGES,\n        all_masks: List[Path] = ALL_MASKS,\n        train_size_coef: int = 0.8,\n        batch_size: int = 8,\n        num_workers: int = 2,\n        input_shape: Tuple[int, int] = (512, 512)\n    ):\n        super().__init__()\n        \n        self.dataset = dataset\n        self.all_images = all_images\n        self.all_masks = all_masks\n        self.save_hyperparameters()\n\n        self.train_transforms, self.val_transforms = self._init_transforms()\n\n    def _init_transforms(self) -> Tuple[Callable, Callable]:\n        train_transforms = [\n            A.Resize(*self.hparams.input_shape),\n            A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n            ToTensorV2(),\n            \n        ]\n\n        val_transforms = [\n            A.Resize(*self.hparams.input_shape),\n            A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n            ToTensorV2(),\n        ]\n\n        return A.Compose(train_transforms), A.Compose(val_transforms)\n\n    def setup(self, stage=None):\n        images_train, images_val, masks_train, masks_val = train_test_split(self.all_images, self.all_masks, train_size=self.hparams.train_size_coef)\n        self.train_dataset = self.dataset(images_train, masks_train, self.train_transforms)\n        self.val_dataset = self.dataset(images_val, masks_val, self.val_transforms)\n\n    def train_dataloader(self):\n        return self._dataloader(self.train_dataset)\n\n    def val_dataloader(self):\n        return self._dataloader(self.val_dataset)\n\n    def _dataloader(self, dataset: RZDDataset) -> DataLoader:\n        return DataLoader(\n            dataset,\n            batch_size=self.hparams.batch_size,\n            num_workers=self.hparams.num_workers,\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:20:34.360534Z","iopub.execute_input":"2022-07-20T07:20:34.360956Z","iopub.status.idle":"2022-07-20T07:20:34.376994Z","shell.execute_reply.started":"2022-07-20T07:20:34.360921Z","shell.execute_reply":"2022-07-20T07:20:34.375508Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def show_batch():\n    nrows = 3\n    ncols = 3\n    batch_size = nrows * ncols\n    data_module = RZDDataModule(batch_size=batch_size)\n    data_module.setup()\n    data_loader = data_module.train_dataloader()\n\n    images, masks = next(iter(data_loader))\n\n    fig, _ = plt.subplots(figsize=(10, 10))\n    for i, (image, mask) in enumerate(zip(images, masks)):\n        plt.subplot(nrows, ncols, i + 1)\n        plt.tight_layout()\n        plt.axis('off')\n\n        image = image.permute(1, 2, 0).numpy()\n        mask = mask.numpy()\n\n        print(image.shape, image.min(), image.max(), image.mean(), image.std())\n        print(mask.shape, mask.min(), mask.max(), mask.mean(), mask.std())\n\n        plt.imshow(image)\n        plt.imshow(mask, alpha=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:20:35.618888Z","iopub.execute_input":"2022-07-20T07:20:35.619298Z","iopub.status.idle":"2022-07-20T07:20:35.630575Z","shell.execute_reply.started":"2022-07-20T07:20:35.619262Z","shell.execute_reply":"2022-07-20T07:20:35.629231Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"show_batch()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:20:36.292608Z","iopub.execute_input":"2022-07-20T07:20:36.293417Z","iopub.status.idle":"2022-07-20T07:20:56.196342Z","shell.execute_reply.started":"2022-07-20T07:20:36.293372Z","shell.execute_reply":"2022-07-20T07:20:56.195143Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def test_model_and_loss():\n    model = smp.UnetPlusPlus(\n                        encoder_name='resnet34', \n                        encoder_depth=5, \n                        encoder_weights=None,\n                        decoder_channels=(512, 256, 128, 64, 16),\n                        encoder_weights=None,\n                        in_channels=3, \n                        classes=4, \n                        activation='sigmoid'\n                    )\n    data_module = RZDDataModule(batch_size=4)\n    data_module.setup()\n    data_loader = data_module.train_dataloader()\n    images, masks = next(iter(data_loader))\n    y_hat = model(images)\n    bce_loss = LOSS_FNS['bce']\n    dice_loss = LOSS_FNS['dice']\n    print(dice_loss(y_hat, masks.type(torch.int64)))","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:41:23.207187Z","iopub.execute_input":"2022-07-19T13:41:23.208265Z","iopub.status.idle":"2022-07-19T13:41:23.221295Z","shell.execute_reply.started":"2022-07-19T13:41:23.208208Z","shell.execute_reply":"2022-07-19T13:41:23.220014Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"test_model_and_loss()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:41:26.362998Z","iopub.execute_input":"2022-07-19T13:41:26.364323Z","iopub.status.idle":"2022-07-19T13:41:54.834489Z","shell.execute_reply.started":"2022-07-19T13:41:26.364266Z","shell.execute_reply":"2022-07-19T13:41:54.833297Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class RZDModel(pl.LightningModule):\n    def __init__(\n        self,\n        loss: str,\n        optimizer: str,\n        learning_rate: float,\n        weight_decay: float,\n        scheduler: str,\n        T_max: int,\n        T_0: int,\n        min_lr: int,\n    ):\n        super().__init__()\n\n        self.save_hyperparameters()\n\n        self.model = self._init_model()\n\n        self.loss_fn = self._init_loss_fn()\n\n#         self.metrics = self._init_metrics()\n\n    def _init_model(self) -> nn.Module:\n        return smp.UnetPlusPlus(\n                    encoder_name='resnet34', \n                    encoder_depth=5, \n                    encoder_weights=None,\n                    decoder_channels=(512, 256, 128, 64, 16),\n                    in_channels=3, \n                    classes=4, \n                    activation=None\n                )\n\n    def _init_loss_fn(self) -> Callable:\n        loss = self.hparams.loss\n        assert loss in LOSS_FNS, 'Choose from exstisting!'\n        return LOSS_FNS[loss]\n\n#     def _init_metrics(self) -> nn.ModuleDict:\n#         train_metrics = MetricCollection({\"train_dice\": Dice()})\n#         val_metrics = MetricCollection({\"val_dice\": Dice()})\n\n#         return nn.ModuleDict(\n#             {\n#                 \"train_metrics\": train_metrics,\n#                 \"val_metrics\": val_metrics,\n#             }\n#         )\n\n    def configure_optimizers(self) -> Dict[str, Any]:\n        optimizer_kwargs = dict(\n            params=self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay\n        )\n        if self.hparams.optimizer == \"Adam\":\n            optimizer = torch.optim.Adam(**optimizer_kwargs)\n        elif self.hparams.optimizer == \"AdamW\":\n            optimizer = torch.optim.AdamW(**optimizer_kwargs)\n        elif self.hparams.optimizer == \"SGD\":\n            optimizer = torch.optim.SGD(**optimizer_kwargs)\n        else:\n            raise ValueError(f\"Unknown optimizer: {self.hparams.optimizer}\")\n\n        if self.hparams.scheduler is not None:\n            if self.hparams.scheduler == \"CosineAnnealingLR\":\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n                    optimizer, T_max=self.hparams.T_max, eta_min=self.hparams.min_lr\n                )\n            elif self.hparams.scheduler == \"CosineAnnealingWarmRestarts\":\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                    optimizer, T_0=self.hparams.T_0, eta_min=self.hparams.min_lr\n                )\n            else:\n                raise ValueError(f\"Unknown scheduler: {self.hparams.scheduler}\")\n\n            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n        else:\n            return {\"optimizer\": optimizer}\n\n    def forward(self, images: torch.Tensor) -> torch.Tensor:\n        return self.model(images)\n\n    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n        return self.shared_step(batch, \"train\")\n\n    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n        self.shared_step(batch, \"val\")\n\n    def shared_step(self, batch: Tuple[torch.Tensor, torch.Tensor], stage: str) -> torch.Tensor:\n        images, masks = batch\n        y_pred = self(images)\n        \n        loss = self.loss_fn(y_pred, masks.type(torch.int64)) #error here\n#         metrics = self.metrics[f\"{stage}_metrics\"](y_pred, masks)\n\n        self._log(loss, metrics={}, stage=stage)\n\n        return loss\n\n    def _log(self, loss: torch.Tensor, metrics: dict, stage: str):\n        on_step = True if stage == \"train\" else False\n        self.log(f\"{stage}_loss\", loss)#, on_step=on_step, on_epoch=True, prog_bar=not on_step)\n#         self.log_dict(metrics, on_step=False, on_epoch=True)\n\n    @classmethod\n    def load_eval_checkpoint(cls, checkpoint_path: Path, device: str) -> nn.Module:\n        module = cls.load_from_checkpoint(checkpoint_path=checkpoint_path).to(device)\n        module.eval()\n\n        return module","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:21:17.181347Z","iopub.execute_input":"2022-07-20T07:21:17.182567Z","iopub.status.idle":"2022-07-20T07:21:17.206549Z","shell.execute_reply.started":"2022-07-20T07:21:17.182520Z","shell.execute_reply":"2022-07-20T07:21:17.205300Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"callbacks = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    pl.seed_everything(hash(\"kek\") % 2**32 - 1)\n    \n    model = RZDModel(LOSS, OPTIMIZER, LEARNING_RATE, WEIGHT_DECAY, SCHEDULER, 0, 0, MIN_LR)\n    data_module = RZDDataModule(batch_size=BATCH_SIZE)\n    trainer = pl.Trainer(\n        logger=wandb_logger,\n        max_epochs=MAX_EPOCHS,\n        fast_dev_run=FAST_DEV_RUN,\n        gpus=GPUS,\n        log_every_n_steps=10,\n        )\n    trainer.fit(model, data_module)\n    return trainer","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:42:03.754081Z","iopub.execute_input":"2022-07-19T13:42:03.755330Z","iopub.status.idle":"2022-07-19T13:42:03.770180Z","shell.execute_reply.started":"2022-07-19T13:42:03.755292Z","shell.execute_reply":"2022-07-19T13:42:03.769163Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:42:04.546309Z","iopub.execute_input":"2022-07-19T13:42:04.546975Z","iopub.status.idle":"2022-07-19T13:42:04.561584Z","shell.execute_reply.started":"2022-07-19T13:42:04.546933Z","shell.execute_reply":"2022-07-19T13:42:04.560418Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"trainer = train()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T13:42:07.598683Z","iopub.execute_input":"2022-07-19T13:42:07.599065Z","iopub.status.idle":"2022-07-19T19:11:45.084691Z","shell.execute_reply.started":"2022-07-19T13:42:07.599032Z","shell.execute_reply":"2022-07-19T19:11:45.080603Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"class TestRZD(RZDDataset):\n    def __init__(self, image_paths: List[Path] = TEST_IMAGES):\n        super().__init__(image_paths)\n        \n    def __getitem__(self, idx: int) -> torch.Tensor:\n        image_path = self.image_paths[idx]\n        image_name = image_path.split('/')[-1]\n        image = self._load_image(image_path)\n        return image, image_name","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:22:08.838178Z","iopub.execute_input":"2022-07-20T07:22:08.838777Z","iopub.status.idle":"2022-07-20T07:22:08.850822Z","shell.execute_reply.started":"2022-07-20T07:22:08.838723Z","shell.execute_reply":"2022-07-20T07:22:08.849164Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"SUBMISSION_PATH='./submit'\nmodel = RZDModel.load_eval_checkpoint('../input/unetplusplus-weights-512px/epoch2-step2463.ckpt', device='cpu')\ntest_dataset = TestRZD(TEST_IMAGES)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:22:39.090590Z","iopub.execute_input":"2022-07-20T07:22:39.090964Z","iopub.status.idle":"2022-07-20T07:22:42.861916Z","shell.execute_reply.started":"2022-07-20T07:22:39.090933Z","shell.execute_reply":"2022-07-20T07:22:42.860913Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:37:53.150689Z","iopub.execute_input":"2022-07-20T07:37:53.151101Z","iopub.status.idle":"2022-07-20T07:37:53.155997Z","shell.execute_reply.started":"2022-07-20T07:37:53.151070Z","shell.execute_reply":"2022-07-20T07:37:53.154907Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def predict(model: torch.nn.Module, dataset: Dataset, savedir: Path = SUBMISSION_PATH) -> None:\n    os.makedirs(SUBMISSION_PATH, exist_ok=True)\n    test_transform = {\n        \"out\": lambda shape: A.Resize(*shape),\n        \"in\": A.Compose(\n            [\n                A.Resize(*(512, 512)),\n                A.augmentations.transforms.Normalize(\n                    mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)\n                ),\n                ToTensorV2(),\n            ]\n        ),\n    }\n    transform_submit = np.vectorize(lambda x: MAP_SUBMIT[x])\n\n    for pair in tqdm(dataset):\n        image, image_name = pair\n        image_tr = test_transform[\"in\"](image=image)[\"image\"]\n        mask = model(image_tr.reshape(1, *image_tr.shape))\n\n        mask_np = (\n            mask.argmax(dim=1).numpy().reshape(512, 512)\n        )  # size depends on your model\n        mask_qhd = test_transform[\"out\"](image.shape[:2])(image=mask_np.astype(np.float64))[\n            \"image\"\n        ].astype(int)\n        cv2.imwrite(\n            os.path.join(SUBMISSION_PATH, image_name), transform_submit(mask_qhd)\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:37:55.865431Z","iopub.execute_input":"2022-07-20T07:37:55.866751Z","iopub.status.idle":"2022-07-20T07:37:55.878742Z","shell.execute_reply.started":"2022-07-20T07:37:55.866690Z","shell.execute_reply":"2022-07-20T07:37:55.877531Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"predict(model, test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T07:37:56.039161Z","iopub.execute_input":"2022-07-20T07:37:56.040049Z","iopub.status.idle":"2022-07-20T08:44:32.689655Z","shell.execute_reply.started":"2022-07-20T07:37:56.040007Z","shell.execute_reply":"2022-07-20T08:44:32.686413Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import shutil","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:47:08.424037Z","iopub.execute_input":"2022-07-20T08:47:08.425547Z","iopub.status.idle":"2022-07-20T08:47:08.433729Z","shell.execute_reply.started":"2022-07-20T08:47:08.425483Z","shell.execute_reply":"2022-07-20T08:47:08.432391Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_archive = shutil.make_archive(SUBMISSION_PATH,'zip',SUBMISSION_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:48:20.545564Z","iopub.execute_input":"2022-07-20T08:48:20.545992Z","iopub.status.idle":"2022-07-20T08:48:21.661052Z","shell.execute_reply.started":"2022-07-20T08:48:20.545960Z","shell.execute_reply":"2022-07-20T08:48:21.659919Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"TEST_MASKS = glob.glob(os.path.join(SUBMISSION_PATH, '*.png'))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:59:17.896338Z","iopub.execute_input":"2022-07-20T08:59:17.896816Z","iopub.status.idle":"2022-07-20T08:59:17.908091Z","shell.execute_reply.started":"2022-07-20T08:59:17.896780Z","shell.execute_reply":"2022-07-20T08:59:17.906670Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"dataset_check = RZDDataset(sorted(TEST_IMAGES), sorted(TEST_MASKS))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T09:03:26.259969Z","iopub.execute_input":"2022-07-20T09:03:26.260471Z","iopub.status.idle":"2022-07-20T09:03:26.268092Z","shell.execute_reply.started":"2022-07-20T09:03:26.260418Z","shell.execute_reply":"2022-07-20T09:03:26.266596Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def show_batch_t():\n    nrows = 3\n    ncols = 3\n    batch_size = nrows * ncols\n\n    fig, _ = plt.subplots(figsize=(20, 20))\n    for i in range(9):\n        image, mask = dataset_check[np.random.randint(0, 1000)]\n        plt.subplot(nrows, ncols, i + 1)\n        plt.tight_layout()\n        plt.axis('off')\n\n        plt.imshow(image)\n        plt.imshow(mask, alpha=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T09:27:36.333720Z","iopub.execute_input":"2022-07-20T09:27:36.334140Z","iopub.status.idle":"2022-07-20T09:27:36.343373Z","shell.execute_reply.started":"2022-07-20T09:27:36.334106Z","shell.execute_reply":"2022-07-20T09:27:36.341663Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"show_batch_t()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T09:29:37.710285Z","iopub.execute_input":"2022-07-20T09:29:37.710821Z","iopub.status.idle":"2022-07-20T09:30:03.991367Z","shell.execute_reply.started":"2022-07-20T09:29:37.710779Z","shell.execute_reply":"2022-07-20T09:30:03.989855Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"show_examples('final', dataset_check[900])","metadata":{"execution":{"iopub.status.busy":"2022-07-20T09:09:46.212214Z","iopub.execute_input":"2022-07-20T09:09:46.212711Z","iopub.status.idle":"2022-07-20T09:09:51.038592Z","shell.execute_reply.started":"2022-07-20T09:09:46.212668Z","shell.execute_reply":"2022-07-20T09:09:51.037537Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}